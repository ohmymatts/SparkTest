{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual o objetivo do comando cache​ ​em Spark?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Delimita ou ajusta o RDD na memoria o que torna a sua leitura mais rápida, já que dispensa que uma nova releitura seja feita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo código implementado em Spark é normalmente mais rápido que a implementação equivalente em\n",
    "MapReduce. Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por causa da sua arquitetura que roda grande parte do processamento na memoria RAM. E suas tarefas apenas executam quando a operação reduce é chamada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual é a função do SparkContext​?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a conexão com um cluster do Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explique com suas palavras o que é Resilient​ ​Distributed​ ​Datasets​ (RDD).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coleção de objetos que são distribuidos em um ou mais partições da memoria. Dessa forma os dados podem ser tratados de forma paralela "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupByKey​ ​é menos eficiente que reduceByKey​ ​em grandes dataset. Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupByKey não é realizado de forma paralela, dessa forma acaba por com todo o principio de clusterização do Apache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explique o que o código Scala abaixo faz:\n",
    "val textFile = sc.textFile(\"hdfs://...\")\n",
    "val counts = textFile.flatMap(line => line.split(\" \"))\n",
    ".map(word => (word, 1))\n",
    ".reduceByKey(_ + _)\n",
    "counts.saveAsTextFile(\"hdfs://...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o arquivo e conta a quantida de pelavras dentro desse arquivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA-HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|in24.inetnebr.com - - [01/Aug/1995:00:00:01 -0400] \"GET /shuttle/missions/sts-68/news/sts-68-mcc-05.txt HTTP/1.0\" 200 1839|\n",
      "|uplherc.upl.com - - [01/Aug/1995:00:00:07 -0400] \"GET / HTTP/1.0\" 304 0                                                   |\n",
      "|uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0                          |\n",
      "|uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0                        |\n",
      "|uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 304 0                           |\n",
      "+--------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arquivo1 = sqlContext.read.text( \"data/access_log_Aug95\")\n",
    "arquivo2 = sqlContext.read.text( \"data/access_log_Jul95\")\n",
    "\n",
    "log_file = arquivo1.union(arquivo2) \n",
    "log_file.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+-----------------------------------------------+------+------------+\n",
      "|host              |timestamp                 |path                                           |status|content_size|\n",
      "+------------------+--------------------------+-----------------------------------------------+------+------------+\n",
      "|in24.inetnebr.com |01/Aug/1995:00:00:01 -0400|/shuttle/missions/sts-68/news/sts-68-mcc-05.txt|200   |1839        |\n",
      "|uplherc.upl.com   |01/Aug/1995:00:00:07 -0400|/                                              |304   |0           |\n",
      "+------------------+--------------------------+-----------------------------------------------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions\n",
    "split_df = log_file.select(regexp_extract('value', r'^([^\\s]+\\s)', 1).alias('host'),\n",
    "                        regexp_extract('value', r'^.*\\[(\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]', 1).alias('timestamp'),\n",
    "                        regexp_extract('value', r'^.*\"\\w+\\s+([^\\s]+)\\s+HTTP.*\"', 1).alias('path'),\n",
    "                        regexp_extract('value', r'^.*\"\\s+([^\\s]+)', 1).cast('integer').alias('status'),\n",
    "                        regexp_extract('value', r'^.*\\s+(\\d+)$', 1).cast('integer').alias('content_size'))\n",
    "split_df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade de hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137979\n"
     ]
    }
   ],
   "source": [
    "unique_hosts = split_df.select('host').distinct().count()\n",
    "print(\"Hosts únicos:\" + unique_hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade de retornos 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20901\n"
     ]
    }
   ],
   "source": [
    "invalid_response = split_df.filter(split_df.status.contains(\"404\")).count()\n",
    "print(\"Total de 404:\" + invalid_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maiores causadores de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_404 = split_df.filter('status=404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|host                        |count|\n",
      "+----------------------------+-----+\n",
      "|hoohoo.ncsa.uiuc.edu        |251  |\n",
      "|piweba3y.prodigy.com        |157  |\n",
      "|jbiagioni.npt.nuwc.navy.mil |132  |\n",
      "|piweba1y.prodigy.com        |114  |\n",
      "|www-d4.proxy.aol.com        |91   |\n",
      "+----------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_404 = group_404.select('host').groupBy('host').count().orderBy('count', ascending=False)\n",
    "most_404.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bytes retornados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
